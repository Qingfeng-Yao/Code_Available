传统计算机视觉技术落伍了吗？不，它们是深度学习的「新动能」
深度学习崛起后，传统计算机视觉方法被淘汰了吗？深度学习扩展了数字图像处理的边界。然而，这并不代表在深度学习崛起之前不断发展进步的传统计算机视觉技术被淘汰。近期，来自爱尔兰垂利理工学院的研究者发表论文，分析了这两种方法的优缺点。该论文旨在促进人们对是否保留经典计算机视觉技术知识进行讨论。此外，这篇论文还探讨了如何结合传统计算机视觉与深度学习。文中提及了多个近期混合方法，这些方法既提升了计算机视觉性能，又解决了不适合深度学习的问题。例如，将传统计算机视觉技术与深度学习结合已经在很多新兴领域流行起来，如深度学习模型尚未得到充分优化的全视野、3D 视觉领域。深度学习 VS 传统计算机视觉深度学习的优势深度学习的快速发展和设备能力的改善（如算力、内存容量、能耗、图像传感器分辨率和光学器件）提升了视觉应用的性能和成本效益，并进一步加快了此类应用的扩展。与传统 CV 技术相比，深度学习可以帮助 CV 工程师在图像分类、语义分割、目标检测和同步定位与地图构建（SLAM）等任务上获得更高的准确率。由于深度学习所用的神经网络是训练得到而非编程得到，因此使用该方法的应用所需的专家分析和微调较少，且能够处理目前系统中的海量可用视频数据。深度学习还具备绝佳的灵活性，因为对于任意用例，CNN 模型和框架均可使用自定义数据集重新训练，这与 CV 算法不同，后者具备更强的领域特定性。以移动机器人的目标检测问题为例，对比这两类计算机视觉算法：传统计算机视觉方法使用成熟的 CV 技术处理目标检测问题，如特征描述子（SIFT、SUR、BRIEF 等）。在深度学习兴起前，图像分类等任务需要用到特征提取步骤，特征即图像中「有趣」、描述性或信息性的小图像块。这一步可能涉及多种 CV 算法，如边缘检测、角点检测或阈值分割算法。从图像中提取出足够多的特征后，这些特征可形成每个目标类别的定义（即「词袋」）。部署阶段中，在其他图像中搜索这些定义。如果在一张图像中找到了另一张图像词袋中的绝大多数特征，则该图像也包含同样的目标（如椅子、马等）。传统 CV 方法的缺陷是：从每张图像中选择重要特征是必要步骤。而随着类别数量的增加，特征提取变得越来越麻烦。要确定哪些特征最能描述不同的目标类别，取决于 CV 工程师的判断和长期试错。此外，每个特征定义还需要处理大量参数，所有参数必须由 CV 工程师进行调整。深度学习引入了端到端学习的概念，即向机器提供的图像数据集中的每张图像均已标注目标类别。因而深度学习模型基于给定数据「训练」得到，其中神经网络发现图像类别中的底层模式，并自动提取出对于目标类别最具描述性和最显著的特征。人们普遍认为 DNN 的性能大大超过传统算法，虽然前者在计算要求和训练时间方面有所取舍。随着 CV 领域中最优秀的方法纷纷使用深度学习，CV 工程师的工作流程出现巨大改变，手动提取特征所需的知识和专业技能被使用深度学习架构进行迭代所需的知识和专业技能取代（见图 1）。图 1：a）传统计算机视觉工作流 vs b）深度学习工作流。（图源：[8]）近年来，CNN 的发展对 CV 领域产生了巨大影响，也使得目标识别能力出现大幅提升。这种爆发与算力的提升、训练数据量的增加密不可分。近期 CV 领域中深度神经网络架构出现井喷并得到广泛应用，这从论文《ImageNet Classification with Deep Convolutional Neural Networks》引用量超 3000 次中可见一斑。CNN 利用卷积核（又称滤波器）来检测图像中的特征（如边）。卷积核是权重矩阵，这些权重被训练用于检测特定特征。如名字所示，CNN 的主要思想是在给定输入图像上空间性地卷积内核，检查是否出现检测所需特征。为了用数值表示出现某个特征的置信度，神经网络执行卷积操作，即计算卷积核与它和输入图像重叠区域的点积（卷积核正在查看的原始图像区域叫做感受野）。为了促进卷积核权重的学习，研究人员向卷积层的输出添加偏置项，并馈入非线性激活函数中。激活函数通常是非线性函数，如 Sigmoid、TanH 和 ReLU。激活函数的选择取决于数据和分类任务的性质。例如，ReLU 具备更多生物表征（大脑中的神经元是否处于激活状态）。因此，在图像识别任务中，ReLU 会得到更好的结果，因为它对梯度消失问题具备更强的抵抗力，而且它能够输出更稀疏、高效的表征。为了加速训练过程，减少网络消耗的内存量，卷积层后通常跟着一个池化层，用于移除输入特征中的冗余部分。例如，最大池化在输入上移动窗口，仅输出窗口中的最大值，从而高效减少图像中的冗余部分，留下重要像素。如图 2 所示，深度 CNN 可能具备多对卷积和池化层。最后，全连接层将上一层压缩为特征向量，然后输出层利用密集网络计算输出类别/特征的分数（置信度或概率）。将该输出输入到回归函数中，如 Softmax 函数，它将所有事物映射为向量且其中所有元素的总和为 1。图 2：CNN 构造块。（图源：[13]）但是深度学习仍然只是 CV 领域的工具。例如，CV 领域中最常用的神经网络是 CNN。那么什么是卷积呢？卷积广泛应用于图像处理技术。（深度学习的优点很明确，本文暂不讨论当前最优算法。）但深度学习并非解决所有问题的万灵药，下文将介绍传统 CV 算法更适合的问题及应用。传统 CV 技术的优势这部分将详细介绍基于特征的传统方法在 CV 任务中能够有效提升性能的原因。这些传统方法包括：尺度不变特征变换（Scale Invariant Feature Transform，SIFT）[14]加速稳健特征（Speeded Up Robust Feature，SURF）[15]基于加速分割测试的特征（Features from Accelerated Segment Test，FAST）[16] 霍夫变换（Hough transform）[17]几何哈希（Geometric hashing）[18]特征描述子（如 SIFT 和 SURF）通常与传统机器学习分类算法（如支持向量机和 K 最近邻算法）结合使用，来解决 CV 问题。深度学习有时会「过犹不及」，传统 CV 技术通常能够更高效地解决问题，所用的代码行数也比深度学习少。SIFT，甚至简单的色彩阈值和像素计数等算法，都不是特定于某个类别的，它们是通用算法，可对任意图像执行同样的操作。与之相反，深度神经网络学得的特征是特定于训练数据的。也就是说，如果训练数据集的构建出现问题，则网络对训练数据集以外的图像处理效果不好。因此，SIFT 等算法通常用于图像拼接/3D 网格重建等应用，这些应用不需要特定类别知识。这些任务也可以通过训练大型数据集来实现，但是这需要巨大的研究努力，为一个封闭应用费这么大劲并不实际。在面对一个 CV 应用时，工程师需要培养选择哪种解决方案的常识。例如，对流水线传送带上的两类产品进行分类，一类是红色一类是蓝色。深度神经网络需要首先收集充足的训练数据。然而，使用简单的色彩阈值方法也能达到同样的效果。一些问题可以使用更简单、快速的技术来解决。如果 DNN 对训练数据以外的数据效果不好，怎么办？在训练数据集有限的情况下，神经网络可能出现过拟合，无法进行有效泛化。手动调参是非常困难的事情，因为 DNN 拥有数百万参数，且它们之间的关系错综复杂。也因此，深度学习模型被批评为黑箱。传统的 CV 技术具备充分的透明性，人们可以判断解决方案能否在训练环境外有效运转。CV 工程师了解其算法可以迁移至的问题，这样一旦什么地方出错，他们可以执行调参，使算法能够有效处理大量图像。现在，传统 CV 技术常用于解决简单问题，这样它们可在低成本微处理器上部署，或者通过突出数据中的特定特征、增强数据或者辅助数据集标注，来限定深度学习技术能解决的问题。本文稍后将讨论，在神经网络训练中可使用多少种图像变换技术。最后，CV 领域存在很多更具挑战性的难题，比如机器人学、增强现实、自动全景拼接、虚拟现实、3D 建模、运动估计、视频稳定、运动捕捉、视频处理和场景理解，这些问题无法通过深度学习轻松实现，但它可以从传统 CV 技术中受益。传统 CV 技术与深度学习的融合传统 CV+深度学习=更好的性能传统 CV 技术和深度学习方法之间存在明确的权衡。经典 CV 算法成熟、透明，且为性能和能效进行过优化；深度学习提供更好的准确率和通用性，但消耗的计算资源也更大。混合方法结合传统 CV 技术和深度学习，兼具这两种方法的优点。它们尤其适用于需要快速实现的高性能系统。机器学习度量和深度网络的混合已经非常流行，因为这可以生成更好的模型。混合视觉处理实现能够带来性能优势，且将乘积累加运算减少到深度学习方法的 130-1000 分之一，帧率相比深度学习方法有 10 倍提升。此外，混合方法使用的内存带宽仅为深度学习方法的一半，消耗的 CPU 资源也少得多。充分利用边缘计算当算法和神经网络推断要在边缘设备上运行时，其延迟、成本、云存储和处理要求比基于云的实现低。边缘计算可以避免网络传输敏感或可确认数据，因此具备更强的隐私性和安全性。结合了传统 CV 和深度学习的混合方法充分利用边缘设备上可获取的异质计算能力。异质计算架构包含 CPU、微控制器协同处理器、数字信号处理器（DSP）、现场可编程逻辑门阵列（FPGA）和 AI 加速设备，通过将不同工作负载分配给最高效的计算引擎来降低能耗。测试实现证明，在 DSP 和 CPU 上分别执行深度学习推断时，前者的目标检测延迟是后者的十分之一。多种混合方法证明了其在边缘应用上的优势。使用混合方法能够高效地整合来自边缘节点传感器的数据。不适合深度学习的问题CV 领域中存在一些难题，如机器人学、增强现实、自动全景拼接、虚拟现实、3D 建模、运动估计、视频稳定、运动捕捉、视频处理和场景理解，它们很难通过深度学习以可微方式轻松实现，而是需要使用其他「传统」技术。下文介绍了 CV 领域中的一些新兴问题，在这些问题中深度学习面临新挑战，而经典 CV 技术能够发挥更大作用。3D 视觉3D 输入的内存大小比传统的 RGB 图像大得多，卷积核必须在三维输入空间中执行卷积（见图 3）。图 3：2D CNN vs. 3D CNN [47]因此，3D CNN 的计算复杂度随着分辨率呈现三次方增长。相比于 2D 图像处理，3D CV 更难，因为增加的维度使得不确定性也随之增加，如遮挡和不同的摄像头角度（见图 4）。 下一节将涉及处理多种 3D 数据表征的解决方案，这些方法具备新架构和预处理步骤，专用于解决上述挑战。几何深度学习（GDL）将深度学习技术扩展到 3D 数据。3D 数据的表征方式多种多样，总体上可分为欧几里得和非欧几里得。3D 欧几里得结构化数据具备底层网格结构，允许全局参数化，此外，它还具备和 2D 图像相同的坐标系统。这使得现有的 2D 深度学习范式和 2D CNN 可应用于 3D 数据。3D 欧几里得数据更适合通过基于体素的方法分析简单的刚性物体，如椅子、飞机等。另一方面，3D 非欧几里得数据不具备网格数组结构，即不允许全局参数化。因此，将经典深度学习技术扩展到此类表征是非常难的任务，近期 [52] 提出的 Pointnet 解决了这个难题。对目标识别有用的连续形状信息常常在转换为体素表征的过程中丢失。使用传统 CV 算法，[53] 提出可应用于体素 CNN（voxel CNN）的一维特征。这种基于平均曲率的新型旋转不变特征提升了体素 CNN 的形状识别性能。该方法应用到当前最优的体素 CNN Octnet 架构时取得了极大成功，它在 ModelNet10 数据集上取得了 1% 的整体准确率提升。SLAM视觉 SLAM 是 SLAM 的子集，它使用视觉系统（而非激光雷达）登记场景中的路标。视觉 SLAM 具备摄影测量的优势（丰富的视觉数据、低成本、轻量级和低能耗），且没有后处理通常需要的繁重计算工作负载。视觉 SLAM 包含环境感知、数据匹配、运动估计、位置更新和新路标登记等步骤。对在不同条件（如 3D 旋转、缩放、光照）中出现的视觉对象建模，以及使用强大的迁移学习技术扩展表征以实现 zero/one shot learning，是一道难题。特征提取和数据表征方法可以有效地减少机器学习模型所需的训练样本数量。图像定位中常使用一种两步方法：位置识别+姿势估计。前者使用词袋方法，通过累积局部图像描述子（如 SIFT）来计算每个图像的全局描述子。每个全局描述子均被存储在数据库中，一同存储的还有生成 3D 点云基准图的摄像头姿势。从 query 图像中提取出类似的全局描述子，数据库中最接近的全局描述子可以通过高效搜索检索出来。最接近全局描述子的摄像头姿势可以帮助我们对 query 图像进行粗略定位。在姿势估计中，使用 Perspective-n-Point (PnP) [13] 和几何验证等算法更准确地计算 query 图像的确切姿势。基于图像的位置识别的成功很大程度上归功于提取图像特征描述子的能力。不幸的是，在对激光雷达扫描图像执行局部特征提取时，没有性能堪比 SIFT 的算法。3D 场景由 3D 点和数据库图像构成。一种方法是将每个 3D 点与一组 SIFT 描述子结合起来，描述子对应该点被三角化的图像特征。然后将这些描述子平均为一个 SIFT 描述子，来描述该点的外观。另一种方法基于 RGB-D 数据构建多模态特征，而不是深度处理。至于深度处理部分，研究者采用基于表面法线的着色方法，因为它对多种任务有效且具备稳健性。另一种使用传统 CV 技术的替代方法提出基于图的层级描述子 Force Histogram Decomposition (FHD)，它可以定义对象的成对结构化子部分之间的空间关系和形状信息。该学习步骤的优势是与传统词袋框架兼容，从而出现结合了结构特征和局部特征的混合表征。360 度摄像头由于球面摄像头的成像特点，每张图像都能够捕捉到 360 度全景场景，消除了对转向选择的限制。球面图像面临的一个主要挑战是超广角鱼眼镜头导致的严重桶形畸变，这增加了受传统人类视觉启发的车道检测和轨迹追踪等方法的实现复杂度。这通常需要额外的预处理步骤，如先验校准（prior calibration）和 deworming。[60] 提出的一种替代方法将导航看作分类问题，从而绕过了预处理步骤，该方法基于原始未校准球面图像找出最优潜在路径方向。全景拼接是该领域的另一个开放性问题。实时拼接方法 [61] 使用一组可变形网格和最终图像，并结合利用稳健像素着色器的输入。另一种方法 [62] 将几何推理（线和消失点）提供的准确率和深度学习技术（边和法线图）实现的更高级数据提取和模式识别结合起来，为室内场景提取结构化数据，并生成布局假设。在稀疏结构化场景中，由于缺乏明显的图像特征，基于特征的图像配准方法通常会失败。这时可使用直接的图像配准方法，如基于相位相关的图像配准算法。[23] 研究了基于判别相关滤波器（DCF）的图像配准技术，证明基于 DCF 的方法优于基于相位相关的方法。数据集标注和增强对于 CV 和深度学习的结合存在一些反驳意见，总结为一句话就是：我们需要重新评估方法，不管是基于规则的方法还是数据驱动方法。从信号处理的传统角度来看，我们了解传统 CV 算法（如 SIFT 和 SURF）的运算内涵，而深度学习无法展示这些意义，你所需要的只是更多数据。这可以被视为巨大的前进，但也有可能是后退。本论文提到了该争论的正反方观点，但是如果未来的方法仅基于数据驱动，那么研究重点应该放在更智能的数据集创建方法上。当前研究的基础问题是：对于特殊应用的高级算法或模型，没有足够的数据。未来，结合自定义数据集和深度学习模型将成为很多研究论文的主题。因此研究者的输出不仅涉及算法或架构，还包括数据集或数据收集方法。数据集标注是深度学习工作流中的主要瓶颈，需要大量的手动标注工作。这在语义分割中尤为明显，因为该领域需要准确标注每一个像素。[20] 讨论了很多有用的半自动流程工具，其中一些利用了 ORB 特征、多边形变形（polygon morphing）、半自动感兴趣区域拟合等算法方法。克服数据缺乏、减少图像分类深度学习模型过拟合现象最容易也最常见的方法是，利用标签不变的图像变换（label-preserving transformation）人为地扩大数据集。该过程叫做数据集增强，指基于已有数据通过剪裁、缩放或旋转等方式生成额外的训练数据。人们希望数据增强步骤需要极少的计算，且可在深度学习训练流程中实现，这样变换后的图像就不必存储在磁盘中了。数据增强使用的传统算法方法包括主成分分析（PCA）、噪声添加、在特征空间的样本之间进行内插或外推，以及基于分割标注建模视觉语境周边物体。本文来源：机器之心Pro 作者：如有侵权请联系删除
